{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae029c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A method to model the relationship between a dependent variable (Y) and a single independent variable (X) using a straight line:\\nY = mX + c'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. What is Simple Linear Regression?\n",
    "'''A method to model the relationship between a dependent variable (Y) and a single independent variable (X) using a straight line:\n",
    "Y = mX + c'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a1d133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Key assumptions of Simple Linear Regression:\\n\\nLinearity: The relationship between X and Y is linear.\\n\\nIndependence: Observations are independent of each other.\\n\\nHomoscedasticity: Constant variance of residuals.\\n\\nNormality: Residuals are normally distributed.\\n\\nNo multicollinearity (only relevant in multiple regression).'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. What are the key assumptions of Simple Linear Regression\n",
    "'''Key assumptions of Simple Linear Regression:\n",
    "\n",
    "Linearity: The relationship between X and Y is linear.\n",
    "\n",
    "Independence: Observations are independent of each other.\n",
    "\n",
    "Homoscedasticity: Constant variance of residuals.\n",
    "\n",
    "Normality: Residuals are normally distributed.\n",
    "\n",
    "No multicollinearity (only relevant in multiple regression).'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "106e79fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The slope, indicating how much Y changes for a one-unit increase in X.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. What does the coefficient m represent in the equation Y=mX+c\n",
    "'''The slope, indicating how much Y changes for a one-unit increase in X.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8362338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The value of Y when X = 0.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. What does the intercept c represent in the equation Y=mX+c\n",
    "'''The value of Y when X = 0.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6355db0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'m= n(∑X Y)−(∑X)(∑Y)/n(∑X^2) - (∑X^2)\\n\\u200b\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5. How do we calculate the slope m in Simple Linear Regression\n",
    "''''m= n(∑X Y)−(∑X)(∑Y)/n(∑X^2) - (∑X^2)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d3520f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The least squares method is used to find the best-fitting line for a set of data points by minimizing the sum of the squared\\n errors between the observed values and the predicted values. This method helps to find the line that best represents the relationship\\n   between the independent variable(s) and the dependent variable.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6. What is the purpose of the least squares method in Simple Linear Regression?\n",
    "\n",
    "'''The least squares method is used to find the best-fitting line for a set of data points by minimizing the sum of the squared\n",
    " errors between the observed values and the predicted values. This method helps to find the line that best represents the relationship\n",
    "   between the independent variable(s) and the dependent variable.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c04b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R², also known as the coefficient of determination, measures the proportion of the variance in the dependent variable that is \\nexplained by the independent variable(s). An R² value close to 1 indicates a strong linear relationship,\\nwhile a value close to 0 indicates a weak or no linear relationship. '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression?\n",
    "\n",
    "'''R², also known as the coefficient of determination, measures the proportion of the variance in the dependent variable that is \n",
    "explained by the independent variable(s). An R² value close to 1 indicates a strong linear relationship,\n",
    "while a value close to 0 indicates a weak or no linear relationship. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44106747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Multiple Linear Regression (MLR) is a statistical method that models the relationship between a dependent variable and two or more independent variables.\\nIt extends the concept of Simple Linear Regression by allowing for multiple predictors.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8.  What is Multiple Linear Regression?\n",
    "\n",
    "'''Multiple Linear Regression (MLR) is a statistical method that models the relationship between a dependent variable and two or more independent variables.\n",
    "It extends the concept of Simple Linear Regression by allowing for multiple predictors.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46422f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main difference between Simple Linear Regression and Multiple Linear Regression is the number of independent variables used to model\\n the relationship between the dependent variable. Simple Linear Regression uses one independent variable, while Multiple Linear Regression uses\\n   two or more independent variables.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#9. What is the main difference between Simple and Multiple Linear Regression?\n",
    "\n",
    "'''The main difference between Simple Linear Regression and Multiple Linear Regression is the number of independent variables used to model\n",
    " the relationship between the dependent variable. Simple Linear Regression uses one independent variable, while Multiple Linear Regression uses\n",
    "   two or more independent variables.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f07d3fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The key assumptions of Multiple Linear Regression include:\\n\\nLinearity: A linear relationship between the independent variables and the dependent variable.\\nIndependence: Each observation is independent of the others.\\nHomoscedasticity: The variance of the residuals is constant across all levels of the independent variables.\\nNormality: The residuals are normally distributed.\\nNo multicollinearity: The independent variables are not highly correlated with each other.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10. What are the key assumptions of Multiple Linear Regression?\n",
    "\n",
    "'''The key assumptions of Multiple Linear Regression include:\n",
    "\n",
    "Linearity: A linear relationship between the independent variables and the dependent variable.\n",
    "Independence: Each observation is independent of the others.\n",
    "Homoscedasticity: The variance of the residuals is constant across all levels of the independent variables.\n",
    "Normality: The residuals are normally distributed.\n",
    "No multicollinearity: The independent variables are not highly correlated with each other.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae85e49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Heteroscedasticity occurs when the variance of the residuals is not constant across all levels of the independent variables.\\nThis can lead to biased and inconsistent estimates of the regression coefficients.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
    "\n",
    "'''Heteroscedasticity occurs when the variance of the residuals is not constant across all levels of the independent variables.\n",
    "This can lead to biased and inconsistent estimates of the regression coefficients.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f3cf458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To improve a Multiple Linear Regression model with high multicollinearity, you can try:\\n\\nRemoving one of the highly correlated variables\\nUsing dimensionality reduction techniques (e.g., PCA)\\nUsing regularization techniques (e.g., Ridge or Lasso regression)\\nTransforming the variables to reduce correlation'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#12. How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
    "\n",
    "'''To improve a Multiple Linear Regression model with high multicollinearity, you can try:\n",
    "\n",
    "Removing one of the highly correlated variables\n",
    "Using dimensionality reduction techniques (e.g., PCA)\n",
    "Using regularization techniques (e.g., Ridge or Lasso regression)\n",
    "Transforming the variables to reduce correlation'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88a9e1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some common techniques for transforming categorical variables include:\\n\\nOne-hot encoding\\nDummy coding\\nLabel encoding\\nOrdinal encoding'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#13.  What are some common techniques for transforming categorical variables for use in regression models?\n",
    "\n",
    "'''Some common techniques for transforming categorical variables include:\n",
    "\n",
    "One-hot encoding\n",
    "Dummy coding\n",
    "Label encoding\n",
    "Ordinal encoding'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b4cf706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Interaction terms are used to model the relationship between two or more independent variables and the dependent variable.\\nThey can help to capture non-linear relationships and interactions between variables.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#14. What is the role of interaction terms in Multiple Linear Regression?\n",
    "\n",
    "'''Interaction terms are used to model the relationship between two or more independent variables and the dependent variable.\n",
    "They can help to capture non-linear relationships and interactions between variables.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd22fdc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In Simple Linear Regression, the intercept represents the expected value of the dependent variable when the independent variable is zero.\\n In Multiple Linear Regression, the intercept represents the expected value of the dependent variable when all independent variables are zero.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#15.  How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
    "\n",
    "'''In Simple Linear Regression, the intercept represents the expected value of the dependent variable when the independent variable is zero.\n",
    " In Multiple Linear Regression, the intercept represents the expected value of the dependent variable when all independent variables are zero.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92e68680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The slope represents the change in the dependent variable for a one-unit change in the independent variable.\\n A significant slope indicates a linear relationship between the variables.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#16. What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
    "\n",
    "'''The slope represents the change in the dependent variable for a one-unit change in the independent variable.\n",
    " A significant slope indicates a linear relationship between the variables.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "039ce92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The intercept provides context by indicating the expected value of the dependent variable when the independent variables are zero.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#17. How does the intercept in a regression model provide context for the relationship between variables?\n",
    "\n",
    "'''The intercept provides context by indicating the expected value of the dependent variable when the independent variables are zero.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "020e38f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"R² is not a perfect measure of model performance, as it can be inflated by adding more independent variables to the model.\\n It's better to use adjusted R² or other metrics to evaluate model performance.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#18. What are the limitations of using R² as a sole measure of model performance?\n",
    "\n",
    "'''R² is not a perfect measure of model performance, as it can be inflated by adding more independent variables to the model.\n",
    " It's better to use adjusted R² or other metrics to evaluate model performance.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ae72418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A large standard error indicates that the regression coefficient is not reliable, and the relationship between the variables may not be statistically significant.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#19. How would you interpret a large standard error for a regression coefficient?\n",
    "\n",
    "'''A large standard error indicates that the regression coefficient is not reliable, and the relationship between the variables may not be statistically significant.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad701925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Heteroscedasticity can be identified by examining the residual plots, which should be randomly scattered around the horizontal axis.\\n If the residuals are not randomly scattered, it may indicate heteroscedasticity.\\n   Addressing heteroscedasticity is important to ensure that the regression coefficients are unbiased and consistent.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
    "\n",
    "'''Heteroscedasticity can be identified by examining the residual plots, which should be randomly scattered around the horizontal axis.\n",
    " If the residuals are not randomly scattered, it may indicate heteroscedasticity.\n",
    "   Addressing heteroscedasticity is important to ensure that the regression coefficients are unbiased and consistent.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1acfd324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A high R² but low adjusted R² indicates that the model is overfitting, meaning it's fitting the noise in the data rather than the underlying relationship.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?\n",
    "\n",
    "'''A high R² but low adjusted R² indicates that the model is overfitting, meaning it's fitting the noise in the data rather than the underlying relationship.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71d3d8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scaling variables is important to prevent multicollinearity and to ensure that the regression coefficients are not influenced by the scale of the variables.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#22. Why is it important to scale variables in Multiple Linear Regression?\n",
    "\n",
    "'''Scaling variables is important to prevent multicollinearity and to ensure that the regression coefficients are not influenced by the scale of the variables.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5aa88c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Polynomial regression is a type of regression analysis that models the relationship between a dependent variable and one or more independent variables using a polynomial function.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#23. What is polynomial regression?\n",
    "\n",
    "'''Polynomial regression is a type of regression analysis that models the relationship between a dependent variable and one or more independent variables using a polynomial function.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32328044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Polynomial regression differs from linear regression in that it uses a polynomial function to model the relationship between the variables, rather than a linear function.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#24. How does polynomial regression differ from linear regression?\n",
    "\n",
    "'''Polynomial regression differs from linear regression in that it uses a polynomial function to model the relationship between the variables, rather than a linear function.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84126eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Polynomial regression is used when the relationship between the variables is non-linear or when there are interactions between the variables.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#25. When is polynomial regression used?\n",
    "\n",
    "'''Polynomial regression is used when the relationship between the variables is non-linear or when there are interactions between the variables.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62445e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The general equation for polynomial regression is:\\n\\ny = β0 + β1x + β2x^2 + ... + βnx^n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#26. What is the general equation for polynomial regression?\n",
    "\n",
    "'''The general equation for polynomial regression is:\n",
    "\n",
    "y = β0 + β1x + β2x^2 + ... + βnx^n\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660628f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, polynomial regression can be applied to multiple variables.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#27.  Can polynomial regression be applied to multiple variables?\n",
    "\n",
    "'''Yes, polynomial regression can be applied to multiple variables.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add1c1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The limitations of polynomial regression include:\\n\\nOverfitting: Polynomial regression can fit the noise in the data rather than the underlying relationship.\\nInterpreting coefficients: The coefficients in polynomial regression can be difficult to interpret.\\nComputational complexity: Polynomial regression can be computationally intensive.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#28. What are the limitations of polynomial regression?\n",
    "\n",
    "'''The limitations of polynomial regression include:\n",
    "\n",
    "Overfitting: Polynomial regression can fit the noise in the data rather than the underlying relationship.\n",
    "Interpreting coefficients: The coefficients in polynomial regression can be difficult to interpret.\n",
    "Computational complexity: Polynomial regression can be computationally intensive.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db557df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Methods for evaluating model fit include:\\n\\nCross-validation\\nAkaike information criterion (AIC)\\nBayesian information criterion (BIC)\\nR-squared'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
    "\n",
    "'''Methods for evaluating model fit include:\n",
    "\n",
    "Cross-validation\n",
    "Akaike information criterion (AIC)\n",
    "Bayesian information criterion (BIC)\n",
    "R-squared'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9506a505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Visualization is important in polynomial regression to:\\n\\nIdentify non-linear relationships\\nVisualize the effects of interactions between variables\\nEvaluate model fit'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#30. Why is visualization important in polynomial regression?\n",
    "\n",
    "'''Visualization is important in polynomial regression to:\n",
    "\n",
    "Identify non-linear relationships\n",
    "Visualize the effects of interactions between variables\n",
    "Evaluate model fit'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0e1a386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Polynomial regression can be implemented in Python using libraries such as scikit-learn or statsmodels.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#31. How is polynomial regression implemented in Python?\n",
    "\n",
    "'''Polynomial regression can be implemented in Python using libraries such as scikit-learn or statsmodels.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6424e654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
